<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Quartz框架中CronTigger周期性调度问题]]></title>
    <url>%2Fblog%2F2019%2F09%2F27%2FQuartz%E6%A1%86%E6%9E%B6%E4%B8%ADCronTigger%E5%91%A8%E6%9C%9F%E6%80%A7%E8%B0%83%E5%BA%A6%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[Quartz框架中CronTigger周期性调度问题一、问题点​ quartz定时任务设置每32秒执行一次，如果CronTigger调度器，cron表达式可能会写成这样：0/32 * * * * ? ， 那么问题来了，调度执行结果为： 123456最近5次运行时间: 2019/9/27 15:12:32 2019/9/27 15:13:00 2019/9/27 15:13:32 2019/9/27 15:14:00 2019/9/27 15:14:32 从结果将会发现，循环周期为32,28秒。如果做分钟的间隔周期也会是一样，不满足需求，特别是有时候超过60的时候，不能被60整除的循环都会出现此问题。如果需求要求可以动态更改调度时间，就更不好做了。Cron表达式对这种方式不是很友好。 二、解决方法​ 这个时候，我们可以选择使用Simple Trigger调度器，在具体的时间点执行一次，或者在具体的时间点执行，并且以指定的间隔重复执行若干次。]]></content>
      <categories>
        <category>定时任务框架</category>
      </categories>
      <tags>
        <tag>quartz</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GitHub+jsDelivr+PicGo搭建免费图床]]></title>
    <url>%2Fblog%2F2019%2F08%2F31%2FGitHub%2BjsDelivr%2BPicGo%E6%90%AD%E5%BB%BA%E5%85%8D%E8%B4%B9%E5%9B%BE%E5%BA%8A%2F</url>
    <content type="text"><![CDATA[GitHub+jsDelivr+PicGo搭建免费图床一、前言​ 1.用 markdown 写博客，想插入一些图片，如果采用本地存储方式，上传博客时插入的图片路径就找不到了，需要手动再把图片上传上去，并且修改路径，很麻烦，可以考虑将图片上传至图床生成 URL，直接在markdown 引入url。 ​ 2.现在国内用的各种图床,例如,微博图床、SM.MS、Imgur、七牛云、又拍云、腾讯云COS、阿里云OSS等都有各种限制，或者需要收费。 ​ 3.使用GitHub仓库创建一个图床，存在的问题是国内访问github的速度不是很快，可以利用jsDelivr CDN加速访问（jsDelivr 是一个免费开源的 CDN 解决方案）国内该平台是首个「打通中国大陆与海外的免费CDN服务」，网页开发者无须担心中国防火墙问题而影响使用。 二、创建Github仓库​ 创建一个github仓库，专门存放上传的图片。 三、生成Access token按照下列步骤依次生成token,生成的token只显示一次,页面关闭后就看不了了,需要先将它复制下来。 四、配置PicGo，使用jsDelivr的CDN下载PicGo软件，安装。下载路径：https://github.com/Molunerfinn/picgo/releases 打开PicGo进行配置 将刚才在Github上创建的仓库名和分支名填入设置中，生成的Token复制到配置中。 指定存储文件夹的路径，PicGo上传文件的时候，将自动在github仓库中创建此文件夹。 自定义域名：这个很有用，如果设置了自定义域名，PicGo生成的访问链接，将是【自定义域名+文件名】的拼接方式。因为我们需要使用jsDelivr加速访问，所以将自定义域名设置为【https://cdn.jsdelivr.net/gh/用户名/图床仓库名 】。 当然PicGo还有许多配置，不懂可以看看PicGo提供的文档，https://picgo.github.io/PicGo-Doc/zh/guide/ 五、使用免费图床下面就可以愉快的图床了，选择需要的图片和格式，复制链接，粘贴到markdown中，就能显示了。]]></content>
      <categories>
        <category>GitHub</category>
      </categories>
      <tags>
        <tag>Lucene</tag>
        <tag>后端</tag>
        <tag>jsDelivr</tag>
        <tag>PicGo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql数据库存储引擎]]></title>
    <url>%2Fblog%2F2019%2F08%2F31%2Fmysql%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E%2F</url>
    <content type="text"><![CDATA[mysql数据库存储引擎一、存储引擎概念数据库就是存放数据的仓库。至于怎么存储，就涉及到存储引擎。 不同的存储引擎使用不同的存储机制、索引机制、锁定水平，根据实际需求选择不同的存储引擎。 二、mysql支持的存储引擎MyISAM、InnoDB、Memory、CSV、Archive 常用的：MyISAM、InnoDB 三、各种存储引擎比较mysql引擎有很多，只介绍以下通用的引擎。 MyISAM引擎不支持事务操作，支持表级锁，支持创建索引，不支持外键，并发性能会低很多（表级锁），存储空间会占用比较小。 InnoDB引擎支持事务操作，支持行级锁，支持创建索引，支持外键，允许并发量更大（行级锁），存储空间会占用比较大。InnoDB是默认的MySQL引擎。 memery 引擎所有表的数据存储在内存中，数据库重启和崩溃数据即将消失。非常适合储存临时数据的临时表以及数据仓库的经纬表。 Archive引擎Archive存储引擎只支持Insert和select操作,Archive存储引擎十分适合储存归档的数据,比如日志。使用行锁实现高并发的而操作。而且Archive存储引擎使用了zlib算法，将数据行进行压缩后储存，压缩比达1:10。 存储引擎的选择1.如果要提供事物能力，并要求实现并发控制，InnoDB是一个好的选择。 2.如果数据表主要用来插入和查询记录，则MyISAM引擎能提供较高的处理效率。 3.如果只是临时存放数据，数据量不大，以选择将数据保存在内存中的Memory引擎。 4.如果只有INSERT和SELECT操作，可以选择Archive，如记录日志信息可以使用Archive。 四、设置表的存储引擎1、查看表的引擎SELECT TABLE_SCHEMA,TABLE_NAME,TABLE_TYPE,ENGINE FROM information_schema.TABLES WHERE TABLE_NAME = ‘TABLE_NAME’; SHOW CREATE TABLE TABLE_NAME；（也可从创建表的sql语句查看）。 SHOW TABLE STATUS where name =’TABLE_NAME’ 2、修改表的引擎ALTER TABLE TABLE_NAME ENGINE = InnoDB; 3.创建表时指定引擎CREATE TABLE TABLE_NAME (ID INT) ENGINE=InnoDB; 一、存储引擎概念数据库就是存放数据的仓库。至于怎么存储，就涉及到存储引擎。 不同的存储引擎使用不同的存储机制、索引机制、锁定水平，根据实际需求选择不同的存储引擎。 二、mysql支持的存储引擎MyISAM、InnoDB、Memory、CSV、Archive 常用的：MyISAM、InnoDB 三、各种存储引擎比较mysql引擎有很多，只介绍以下通用的引擎。 MyISAM引擎不支持事务操作，支持表级锁，支持创建索引，不支持外键，并发性能会低很多（表级锁），存储空间会占用比较小。 InnoDB引擎支持事务操作，支持行级锁，支持创建索引，支持外键，允许并发量更大（行级锁），存储空间会占用比较大。InnoDB是默认的MySQL引擎。 memery 引擎所有表的数据存储在内存中，数据库重启和崩溃数据即将消失。非常适合储存临时数据的临时表以及数据仓库的经纬表。 Archive引擎Archive存储引擎只支持Insert和select操作,Archive存储引擎十分适合储存归档的数据,比如日志。使用行锁实现高并发的而操作。而且Archive存储引擎使用了zlib算法，将数据行进行压缩后储存，压缩比达1:10。 存储引擎的选择1.如果要提供事物能力，并要求实现并发控制，InnoDB是一个好的选择。 2.如果数据表主要用来插入和查询记录，则MyISAM引擎能提供较高的处理效率。 3.如果只是临时存放数据，数据量不大，以选择将数据保存在内存中的Memory引擎。 4.如果只有INSERT和SELECT操作，可以选择Archive，如记录日志信息可以使用Archive。 四、设置表的存储引擎1、查看表的引擎SELECT TABLE_SCHEMA,TABLE_NAME,TABLE_TYPE,ENGINE FROM information_schema.TABLES WHERE TABLE_NAME = ‘TABLE_NAME’; SHOW CREATE TABLE TABLE_NAME；（也可从创建表的sql语句查看）。 SHOW TABLE STATUS where name =’TABLE_NAME’ 2、修改表的引擎ALTER TABLE TABLE_NAME ENGINE = InnoDB; 3.创建表时指定引擎CREATE TABLE TABLE_NAME (ID INT) ENGINE=InnoDB;]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>数据库</tag>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用Navicat生成RE关系图]]></title>
    <url>%2Fblog%2F2019%2F08%2F31%2F%E4%BD%BF%E7%94%A8Navicat%E7%94%9F%E6%88%90ER%E5%9B%BE%2F</url>
    <content type="text"><![CDATA[使用Navicat生成ER图1.ER图​ E-R图也称实体-联系图(Entity Relationship Diagram)，提供了表示实体类型、属性和联系的方法,开发的时候往往需要有ER图. 2.常用工具​ Visio:可以以更直观的方式创建图表的新功能,但是如果要画表关系的话,需要一个个去打,没有逆向生成模型的功能. ​ PowerDesigner:是一款非常全面的数据库设计工具,支持表与表之间建立关系,界面简洁，功能强大,这个可以选用. ​ Navicat:非常好用的数据库管理工具,可以逆向生成模型. 3.使用Navicat生成关系图​ 1.新建模型 ​ 新建模型,将需要的表拖入模型中,如果表与表之间存在外键,将自动生成外键关系图. ​ 2.添加外键 ​ 现在数据库建表其实都不适合使用外键,使用外键,极易受到数据库服务器的瓶颈,而且不容易扩展。尤其是现在的互联网产品，数据量大，并发高，更不适合使用外键。所有的外键约束，需要应用程序来实现，牺牲应用服务器的资源，换取数据库服务器的性能。 ​ 那么表与表之间没有外键，表关系在代码中，ER图又想体现出关系来，在navicat中该怎么做呢？ ​ 3.导出模型 ​ 模型创建好了可以保存为npm格式，下次使用navicat可以再修改，很多时候，需要转换成PDF格式，可以使用navicat转换。]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>数据库</tag>
        <tag>navicat</tag>
        <tag>ER图</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用批处理方式配置Java环境]]></title>
    <url>%2Fblog%2F2019%2F08%2F30%2F%E4%BD%BF%E7%94%A8%E6%89%B9%E5%A4%84%E7%90%86%E6%96%B9%E5%BC%8F%E9%85%8D%E7%BD%AEJava%E7%8E%AF%E5%A2%83%2F</url>
    <content type="text"><![CDATA[使用批处理方式配置Java环境一、需求点​ 1.公司的现场维护人员配置java环境不熟练，容易配错； ​ 2.项目中使用到elasticsearch（2.3.2版本），一定要配置JAVA_HOME; ​ 2.项目也是必须要在jdk8以上版本运行； 二、解决方案​ 为解决以上问题点，使用批处理来配置环境变量。 ​ 大致思路分三步： ​ 1.安装好JDK； ​ 2.判断现在服务器上安装的jdk版本，如果是8以上版本则不配置； ​ 3.配置JAVA_HOME和path。 ​ 注意点： ​ 批处理文件需要与jdk放在同级目录，JAVA_HOME /M “%bbd%\jdk1.8.0_144”，这个路径需要手动修改成自己JDK的路径。 123456789101112131415161718192021222324252627282930313233@echo offREM 检查JDK环境和NODEJS环境pushd %~dp0cd..set bjava=0set &quot;bbd=%cd%&quot;java -version&gt;nul 2&gt;nulif /i not %errorlevel% == 0 (set bjava=1goto ENDJAVA) else GOTO CHECKJAVA:CHECKJAVAfor /f &quot;tokens=3&quot; %%g in (&apos;java -version 2^&gt;^&amp;1 ^| findstr /i &quot;version&quot;&apos;) do ( set JAVAVER=%%g)set JAVAVER=%JAVAVER:&quot;=%for /f &quot;delims=. tokens=1-3&quot; %%v in (&quot;%JAVAVER%&quot;) do ( set CURRENTV=%%w)if %CURRENTV% LSS 8 (set bjava=1):ENDJAVAif %bjava% equ 1 ( setx JAVA_HOME /M &quot;%bbd%\jdk1.8.0_144&quot; setx Path /M &quot;%%JAVA_HOME%%\bin;%PATH%&quot;)pauseecho **********************************************echo jdk环境已配置好,请按任意键继续!pause]]></content>
      <categories>
        <category>批处理</category>
      </categories>
      <tags>
        <tag>池处理</tag>
        <tag>java基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库索引相关问题点]]></title>
    <url>%2Fblog%2F2019%2F08%2F29%2F%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B4%A2%E5%BC%95%2F</url>
    <content type="text"><![CDATA[数据库索引1.为什么要给表加上主键？ 没有创建主键的表,他的数据是无序的放在磁盘中,一行行的排列很整齐,查询时也要一行行的扫描。 创建了主键的表，在磁盘中的存储结构，由整齐的结构变成树状结构，也就是平衡树（B-Tree，B+Tree）结构。整个变成一个索引，也就是所谓的「聚集索引」。 当然，也有使用哈希结构的索引，主流的关系型数据库还是默认平衡树作为索引数据结构的。​ 不同的数据库存储引擎，创建的索引结构也不同。 2.为什么一个表只能有一个主键？一个表只能有一个「聚集索引」，因为主键的作用是把表的数据格式转化为树形结构放置，所以一个表只有一个主键。​ 联合主键是主键的一种,是由多个字段组成的主键,主键并不一定只有一个字段,这里要搞清楚。 3.为什么加索引后会使查询变快？​ select * from table where id=82； ​ 假如一张他table表有一亿条数据 ，需要查找id为82的数据，没创建索引的情况，可能是一条一条的去匹配，最差的打算是需要匹配一亿次，一亿次匹配查询，就是一亿次IO开销，按照服务器的I/O能力与CPU的运算能力，需要几个月才能得出结果。 ​ 往table表中添加id为主键，表的数据结构变化为平衡树结构。 ​ ​ 树形结构：由根节(root)、分支(branches)、叶(leaves)三级节点组成，其中分支节点可以有多层。 ​ 下图展示定位id为82的过程： ​ 算法步骤： ​ 1.读取root节点，判断82大于在0-120之间，走左边分支； ​ 2.读取左边branch节点，判断82大于80且小于等于120，走右边分支； ​ 3.读取右边leaf节点，在该节点中找到数据82及对应的id； ​ 4.使用rowid去物理表中读取记录数据块。 在整个索引中，只进行了三次I/O操作，就定位到了id。 对于一亿的数据量最多要查询多少次呢？ 树形结构，数据每增加一层，数据量就是成指数级的增长。 如果有2个分支,一亿条数据,最多查询27次就可以定位到数据,如果树结构是4个分叉,最多15次就能查到. 4.为什么加索引后会使写入、修改、删除变慢？​ 原因很简单，删改数据都会改变平衡树各节点中的索引数据内容，破坏树结构，每次数据改变时，数据库管理系统都要重新梳理树结构，还会带来不小的性能开销。索引会给查询以外的操作带来副作用。 5.非聚集索引是怎样的呢？​ 非聚集索引，就是我们平时使用的向某个字段添加索引，非聚集索引和聚集索引一样，同样可以采用平衡树作为索引数据结构，索引树各节点中的值，来自于表中字段的值，如果给字段创建一个索引，字段的值就会被复制出来，用于创建索引。给表添加索引，就会增加表的体积，占用更多的磁盘存储空间。非聚集索引都是独立存在的，每个索引之间不存在关联。 6.聚集索引和非聚集索引的区别？​ 通过聚集索引可以查到需要查找到的是每行的数据，通过非聚集索引查到的是记录对应的主键，再通过主键查找相应的值。不管任何查表的方式，都会通过主键定位到数据，聚集索引（主键）是通往数据的唯一途径。 7.什么情况下要同时在两个字段上建索引？​ 可能还有一种特殊情况，可以不通过聚集索引就得到需要的数据，这种非主流的方法 称之为「覆盖索引」查询。也就是平时创建的复合索引或者多字段索引查询。为一个索引指定两个字段，那么两个字段的内容就同步到索引中。如果通过其中的一个字段查另一个字段时，正好在索引中有存储，就不用通过聚集索引啦。 //创建用户的index_name_and_age 索引 1create index index_name_and_age on user_info(name, age); //通过用户名查找年龄 1select age from user where name = &apos;科比&apos;; 这种情况,可以创建复合索引了。]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>数据库</tag>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot+Lucene案例介绍]]></title>
    <url>%2Fblog%2F2019%2F06%2F07%2FSpringBoot%2BLucene%E6%A1%88%E4%BE%8B%2F</url>
    <content type="text"><![CDATA[SpringBoot+Lucene案例介绍一、案例介绍 模拟一个商品的站内搜索系统（类似淘宝的站内搜索）； 商品详情保存在mysql数据库的product表中，使用mybatis框架； 站内查询使用Lucene创建索引，进行全文检索； 增、删、改，商品需要对Lucene索引修改，搜索也要达到近实时的效果。 对于数据库的操作和配置就不在本文中体现，主要讲解与Lucene的整合。 一、引入lucene的依赖向pom文件中引入依赖 123456789101112131415161718192021222324252627282930&lt;!--核心包--&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.lucene&lt;/groupId&gt; &lt;artifactId&gt;lucene-core&lt;/artifactId&gt; &lt;version&gt;7.6.0&lt;/version&gt;&lt;/dependency&gt;&lt;!--对分词索引查询解析--&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.lucene&lt;/groupId&gt; &lt;artifactId&gt;lucene-queryparser&lt;/artifactId&gt; &lt;version&gt;7.6.0&lt;/version&gt;&lt;/dependency&gt;&lt;!--一般分词器，适用于英文分词--&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.lucene&lt;/groupId&gt; &lt;artifactId&gt;lucene-analyzers-common&lt;/artifactId&gt; &lt;version&gt;7.6.0&lt;/version&gt;&lt;/dependency&gt;&lt;!--检索关键字高亮显示 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.lucene&lt;/groupId&gt; &lt;artifactId&gt;lucene-highlighter&lt;/artifactId&gt; &lt;version&gt;7.6.0&lt;/version&gt;&lt;/dependency&gt;&lt;!-- smartcn中文分词器 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.lucene&lt;/groupId&gt; &lt;artifactId&gt;lucene-analyzers-smartcn&lt;/artifactId&gt; &lt;version&gt;7.6.0&lt;/version&gt;&lt;/dependency&gt; 三、配置初始化Bean类初始化bean类需要知道的几点： 1.实例化 IndexWriter，IndexSearcher 都需要去加载索引文件夹，实例化是是非常消耗资源的，所以我们希望只实例化一次交给spring管理。 2.IndexSearcher 我们一般通过SearcherManager管理，因为IndexSearcher 如果初始化的时候加载了索引文件夹，那么 后面添加、删除、修改的索引都不能通过IndexSearcher 查出来，因为它没有与索引库实时同步，只是第一次有加载。 3.ControlledRealTimeReopenThread创建一个守护线程，如果没有主线程这个也会消失，这个线程作用就是定期更新让SearchManager管理的search能获得最新的索引库，下面是每25S执行一次。 4.要注意引入的lucene版本，不同的版本用法也不同，许多api都有改变。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172@Configurationpublic class LuceneConfig &#123; /** * lucene索引,存放位置 */ private static final String LUCENEINDEXPATH=&quot;lucene/indexDir/&quot;; /** * 创建一个 Analyzer 实例 * * @return */ @Bean public Analyzer analyzer() &#123; return new SmartChineseAnalyzer(); &#125; /** * 索引位置 * * @return * @throws IOException */ @Bean public Directory directory() throws IOException &#123; Path path = Paths.get(LUCENEINDEXPATH); File file = path.toFile(); if(!file.exists()) &#123; //如果文件夹不存在,则创建 file.mkdirs(); &#125; return FSDirectory.open(path); &#125; /** * 创建indexWriter * * @param directory * @param analyzer * @return * @throws IOException */ @Bean public IndexWriter indexWriter(Directory directory, Analyzer analyzer) throws IOException &#123; IndexWriterConfig indexWriterConfig = new IndexWriterConfig(analyzer); IndexWriter indexWriter = new IndexWriter(directory, indexWriterConfig); // 清空索引 indexWriter.deleteAll(); indexWriter.commit(); return indexWriter; &#125; /** * SearcherManager管理 * * @param directory * @return * @throws IOException */ @Bean public SearcherManager searcherManager(Directory directory, IndexWriter indexWriter) throws IOException &#123; SearcherManager searcherManager = new SearcherManager(indexWriter, false, false, new SearcherFactory()); ControlledRealTimeReopenThread cRTReopenThead = new ControlledRealTimeReopenThread(indexWriter, searcherManager, 5.0, 0.025); cRTReopenThead.setDaemon(true); //线程名称 cRTReopenThead.setName(&quot;更新IndexReader线程&quot;); // 开启线程 cRTReopenThead.start(); return searcherManager; &#125;&#125; 四、创建需要的Bean类创建商品Bean 12345678910111213141516171819202122232425262728293031/** * 商品bean类 * @author yizl * */public class Product &#123; /** * 商品id */ private int id; /** * 商品名称 */ private String name; /** * 商品类型 */ private String category; /** * 商品价格 */ private float price; /** * 商品产地 */ private String place; /** * 商品条形码 */ private String code; ...... 创建一个带参数查询分页通用类PageQuery类 123456789101112131415161718192021222324252627/** * 带参数查询分页类 * @author yizl * * @param &lt;T&gt; */public class PageQuery&lt;T&gt; &#123; private PageInfo pageInfo; /** * 排序字段 */ private Sort sort; /** * 查询参数类 */ private T params; /** * 返回结果集 */ private List&lt;T&gt; results; /** * 不在T类中的参数 */ private Map&lt;String, String&gt; queryParam; ...... 五、创建索引库1.项目启动后执行同步数据库方法项目启动后，更新索引库中所有的索引。 1234567891011121314151617181920/** * 项目启动后,立即执行 * @author yizl * */@Component@Order(value = 1)public class ProductRunner implements ApplicationRunner &#123; @Autowired private ILuceneService service; @Override public void run(ApplicationArguments arg0) throws Exception &#123; /** * 启动后将同步Product表,并创建index */ service.synProductCreatIndex(); &#125;&#125; 2.从数据库中查询出所有的商品从数据库中查找出所有的商品 1234567@Overridepublic void synProductCreatIndex() throws IOException &#123; // 获取所有的productList List&lt;Product&gt; allProduct = mapper.getAllProduct(); // 再插入productList luceneDao.createProductIndex(allProduct);&#125; 3.创建这些商品的索引把List中的商品创建索引 我们知道，mysql对每个字段都定义了字段类型，然后根据类型保存相应的值。 那么lucene的存储对象是以document为存储单元，对象中相关的属性值则存放到Field（域）中； Field类的常用类型 Field类 数据类型 是否分词 index是否索引 Stored是否存储 说明 StringField 字符串 N Y Y/N 构建一个字符串的Field,但不会进行分词,将整串字符串存入索引中,适合存储固定(id,身份证号,订单号等) FloatPointLongPointDoublePoint 数值型 Y Y N 这个Field用来构建一个float数字型Field，进行分词和索引，比如(价格) StoredField 重载方法,，支持多种类型 N N Y 这个Field用来构建不同类型Field,不分析，不索引，但要Field存储在文档中 TextField 字符串或者流 Y Y Y/N 一般此对字段需要进行检索查询 上面是一些常用的数据类型, 6.0后的版本，数值型建立索引的字段都更改为Point结尾，FloatPoint，LongPoint，DoublePoint等，对于浮点型的docvalue是对应的DocValuesField，整型为NumericDocValuesField，FloatDocValuesField等都为NumericDocValuesField的实现类。 commit()的用法commit()方法,indexWriter.addDocuments(docs);只是将文档放在内存中,并没有放入索引库,没有commit()的文档,我从索引库中是查询不出来的; 许多博客代码中,都没有进行commit(),但仍然能查出来,因为每次插入,他都把IndexWriter关闭.close(),Lucene关闭前,都会把在内存的文档,提交到索引库中,索引能查出来,在spring中IndexWriter是单例的,不关闭,所以每次对索引都更改时,都需要进行commit()操作; 这样设计的目的,和数据库的事务类似,可以进行回滚,调用rollback()方法进行回滚。 1234567891011121314151617181920212223242526@Autowiredprivate IndexWriter indexWriter;@Overridepublic void createProductIndex(List&lt;Product&gt; productList) throws IOException &#123; List&lt;Document&gt; docs = new ArrayList&lt;Document&gt;(); for (Product p : productList) &#123; Document doc = new Document(); doc.add(new StringField(&quot;id&quot;, p.getId()+&quot;&quot;, Field.Store.YES)); doc.add(new TextField(&quot;name&quot;, p.getName(), Field.Store.YES)); doc.add(new StringField(&quot;category&quot;, p.getCategory(), Field.Store.YES)); // 保存price, float price = p.getPrice(); // 建立倒排索引 doc.add(new FloatPoint(&quot;price&quot;, price)); // 正排索引用于排序、聚合 doc.add(new FloatDocValuesField(&quot;price&quot;, price)); // 存储到索引库 doc.add(new StoredField(&quot;price&quot;, price)); doc.add(new TextField(&quot;place&quot;, p.getPlace(), Field.Store.YES)); doc.add(new StringField(&quot;code&quot;, p.getCode(), Field.Store.YES)); docs.add(doc); &#125; indexWriter.addDocuments(docs); indexWriter.commit();&#125; 六、多条件查询按条件查询,分页查询都在下面代码中体现出来了,有什么不明白的可以单独查询资料,下面的匹配查询已经比较复杂了. searcherManager.maybeRefresh()方法,刷新searcherManager中的searcher,获取到最新的IndexSearcher。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263@Autowiredprivate Analyzer analyzer;@Autowiredprivate SearcherManager searcherManager;@Overridepublic PageQuery&lt;Product&gt; searchProduct(PageQuery&lt;Product&gt; pageQuery) throws IOException, ParseException &#123; searcherManager.maybeRefresh(); IndexSearcher indexSearcher = searcherManager.acquire(); Product params = pageQuery.getParams(); Map&lt;String, String&gt; queryParam = pageQuery.getQueryParam(); Builder builder = new BooleanQuery.Builder(); Sort sort = new Sort(); // 排序规则 com.infinova.yimall.entity.Sort sort1 = pageQuery.getSort(); if (sort1 != null &amp;&amp; sort1.getOrder() != null) &#123; if (&quot;ASC&quot;.equals((sort1.getOrder()).toUpperCase())) &#123; sort.setSort(new SortField(sort1.getField(), SortField.Type.FLOAT, false)); &#125; else if (&quot;DESC&quot;.equals((sort1.getOrder()).toUpperCase())) &#123; sort.setSort(new SortField(sort1.getField(), SortField.Type.FLOAT, true)); &#125; &#125; // 模糊匹配,匹配词 String keyStr = queryParam.get(&quot;searchKeyStr&quot;); if (keyStr != null) &#123; // 输入空格,不进行模糊查询 if (!&quot;&quot;.equals(keyStr.replaceAll(&quot; &quot;, &quot;&quot;))) &#123; builder.add(new QueryParser(&quot;name&quot;, analyzer).parse(keyStr), Occur.MUST); &#125; &#125; // 精确查询 if (params.getCategory() != null) &#123; builder.add(new TermQuery(new Term(&quot;category&quot;, params.getCategory())), Occur.MUST); &#125; if (queryParam.get(&quot;lowerPrice&quot;) != null &amp;&amp; queryParam.get(&quot;upperPrice&quot;) != null) &#123; // 价格范围查询 builder.add(FloatPoint.newRangeQuery(&quot;price&quot;, Float.parseFloat(queryParam.get(&quot;lowerPrice&quot;)), Float.parseFloat(queryParam.get(&quot;upperPrice&quot;))), Occur.MUST); &#125; PageInfo pageInfo = pageQuery.getPageInfo(); TopDocs topDocs = indexSearcher.search(builder.build(), pageInfo.getPageNum() * pageInfo.getPageSize(), sort); pageInfo.setTotal(topDocs.totalHits); ScoreDoc[] hits = topDocs.scoreDocs; List&lt;Product&gt; pList = new ArrayList&lt;Product&gt;(); for (int i = 0; i &lt; hits.length; i++) &#123; Document doc = indexSearcher.doc(hits[i].doc); System.out.println(doc.toString()); Product product = new Product(); product.setId(Integer.parseInt(doc.get(&quot;id&quot;))); product.setName(doc.get(&quot;name&quot;)); product.setCategory(doc.get(&quot;category&quot;)); product.setPlace(doc.get(&quot;place&quot;)); product.setPrice(Float.parseFloat(doc.get(&quot;price&quot;))); product.setCode(doc.get(&quot;code&quot;)); pList.add(product); &#125; pageQuery.setResults(pList); return pageQuery;&#125; 七、删除更新索引12345@Overridepublic void deleteProductIndexById(String id) throws IOException &#123; indexWriter.deleteDocuments(new Term(&quot;id&quot;,id)); indexWriter.commit();&#125; 八、补全Spring中剩余代码Controller层 1234567891011121314151617181920@RestController@RequestMapping(&quot;/product/search&quot;)public class ProductSearchController &#123; @Autowired private ILuceneService service; /** * * @param pageQuery * @return * @throws ParseException * @throws IOException */ @PostMapping(&quot;/searchProduct&quot;) private ResultBean&lt;PageQuery&lt;Product&gt;&gt; searchProduct(@RequestBody PageQuery&lt;Product&gt; pageQuery) throws IOException, ParseException &#123; PageQuery&lt;Product&gt; pageResult= service.searchProduct(pageQuery); return ResultUtil.success(pageResult); &#125; &#125; 12345678910111213141516171819public class ResultUtil&lt;T&gt; &#123; public static &lt;T&gt; ResultBean&lt;T&gt; success(T t)&#123; ResultEnum successEnum = ResultEnum.SUCCESS; return new ResultBean&lt;T&gt;(successEnum.getCode(),successEnum.getMsg(),t); &#125; public static &lt;T&gt; ResultBean&lt;T&gt; success()&#123; return success(null); &#125; public static &lt;T&gt; ResultBean&lt;T&gt; error(ResultEnum Enum)&#123; ResultBean&lt;T&gt; result = new ResultBean&lt;T&gt;(); result.setCode(Enum.getCode()); result.setMsg(Enum.getMsg()); result.setData(null); return result; &#125;&#125; 1234567891011121314151617public class ResultBean&lt;T&gt; implements Serializable &#123; private static final long serialVersionUID = 1L; /** * 返回code */ private int code; /** * 返回message */ private String msg; /** * 返回值 */ private T data; ... 12345678910111213141516171819public enum ResultEnum &#123; UNKNOW_ERROR(-1, &quot;未知错误&quot;), SUCCESS(0, &quot;成功&quot;), PASSWORD_ERROR(10001, &quot;用户名或密码错误&quot;), PARAMETER_ERROR(10002, &quot;参数错误&quot;); /** * 返回code */ private Integer code; /** * 返回message */ private String msg; ResultEnum(Integer code, String msg) &#123; this.code = code; this.msg = msg; &#125;]]></content>
      <categories>
        <category>全文检索技术</category>
      </categories>
      <tags>
        <tag>SpringBoot</tag>
        <tag>Lucene</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JDK的动态代理]]></title>
    <url>%2Fblog%2F2019%2F06%2F07%2Fjava%E7%9A%84%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86%2F</url>
    <content type="text"><![CDATA[JDK的动态代理一、静态代理了解动态代理前，有必要先讲解下静态代理。 举个例子：银行开通了短信业务，在你取钱，存钱，转账后都会 给你发送短信，我们来模拟下业务场景。 静态代理的实现下面来模拟下业务代码 1.定义IBankCardService接口/** * 银行卡操作接口 * @author yizl * */ public interface IBankCardService { /** * 存钱 * @param cardId */ public void putInMoney(String cardId); /** * 取钱 * @param cardId */ public void outMoney(String cardId); /** * 查询余额 * @param cardId */ public String getMoney(String cardId); }2.接口实现(BankCardServiceImpl)/** * 银行卡操作实现类 * @author yizl * */ public class BankCardServiceImpl implements IBankCardService { @Override public void putInMoney(String cardId) { System.out.println(&quot;开始往银行卡账号为:&quot;+cardId+&quot; 存钱&quot;); } @Override public void outMoney(String cardId) { System.out.println(&quot;向银行卡账号为:&quot;+cardId+&quot; 取钱&quot;); } @Override public String getMoney(String cardId) { System.out.println(&quot;查询银行卡账号为:&quot;+cardId+&quot; 的余额&quot;); return null; } }3.编写代理类假设项目经理有个需求:在每次业务操作后都需要向用户发送短信. 在不修改已有的实现类的前提下怎么实现这个需求. 1.我们写一个代理类,让它与银行卡操作实现类的接口相同. 2.在代理类的构造器中,传入银行卡操作实现类,在代理类的方法内部仍然调用银行卡操作实现类的方法. 代理类 /** * 代理银行卡操作实现类 * @author yizl * */ public class ProxyBankCardServiceImpl implements IBankCardService { private IBankCardService bankCardService; public ProxyBankCardServiceImpl(IBankCardService bankCardService) { this.bankCardService=bankCardService; } @Override public void putInMoney(String cardId) { bankCardService.putInMoney(cardId); System.out.println(&quot;向客户发送短信&quot;); } @Override public void outMoney(String cardId) { bankCardService.outMoney(cardId); System.out.println(&quot;向客户发送短信&quot;); } @Override public String getMoney(String cardId) { bankCardService.getMoney(cardId); System.out.println(&quot;向客户发送短信&quot;); return null; } }4.调用代理类public class ProxyTest { public static void main(String[] args) { IBankCardService bankCardService =new BankCardServiceImpl(); IBankCardService proxyBankCard=new ProxyBankCardServiceImpl(bankCardService); proxyBankCard.putInMoney(&quot;9527&quot;); } } 打印结果: 开始往银行卡账号为:9527的账户存钱 向客户发送短信可以看出,代理类的作用:代理对象=增强代码+目标对象 代理类只对银行卡操作实现类进行增强，每个方法都添加发送短信业务，真正业务还是在银行卡操作实现类中在进行。 静态代理的缺点我们发现静态代码其实很麻烦,有点脱裤子放屁的意思. 静态代理的缺点： ​ 1.要为每一个目标类都要编写相应的代理类，会有很多代理类。 ​ 2.接口改了，目标类和代理类都要跟着改。 二、动态代理我们只想写增强的代码，不需要写代理类，增强代码还可以复用到不同的目标类。这时动态代理横空出世了。 动态代理实现1、获取代理类方式一1.JDK提供了 java.lang.reflect.Proxy类有一个getProxyClass(ClassLoader, interfaces)静态方法,传入类加载器,和接口,就可以得到代理类的Class对象. 2.得到了代理类的class对象,通过代理类的class对象得到构造器,java.lang.reflect.InvocationHandler类中,每一个动态代理类都要实现InvocationHandler接口,动态代理对象调用一个方法时,就会转到实现InvocationHandler接口类的invoke方法. 3.得到代理类,实行调用. public class ProxyTest { public static void main(String[] args) throws Exception { //目标对象 IBankCardService bankCard=new BankCardServiceImpl(); //获取代理对象 IBankCardService proxyBank = (IBankCardService) getProxy(bankCard); //调用方法 proxyBank.getMoney(&quot;9527&quot;); } /** * 获取代理类 * @param target 目标类 * @return * @throws SecurityException * @throws NoSuchMethodException */ private static Object getProxy(Object target) throws Exception { //得到代理类大class Class proxyClass = Proxy.getProxyClass(target.getClass().getClassLoader(), target.getClass().getInterfaces()); //创建代理类的构造函数,构造函数的方法必须传入InvocationHandler接口的实现类 Constructor constructor=proxyClass.getConstructor(InvocationHandler.class); //获取代理类 Object proxy =constructor.newInstance(new InvocationHandler() { @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { //调用目标文件的方法 Object resulet = method.invoke(target,args); //增强方法 System.out.println(&quot;向客户发送短信&quot;); return resulet; } }); return proxy; } } 打印结果: 查询银行卡账号为:9527的账户 的余额 向客户发送短信2、获取代理类方式二实际变成中不会使用getProxyClass(),因为JDK的Proxy类提供了更好用的方法newProxyInstance(ClassLoader loader, Class&lt;?&gt;[] interfaces,InvocationHandler h),直接传入InvocationHandler 实现类就可以的到代理类. 1.代理类的调用处理程序实现 /** * 发送短信调用类 * @author yizl * */ public class SendMessageInvocation implements InvocationHandler { /** * 目标类 */ private Object obj; /** * 通过构造方法传参 * @param obj */ public SendMessageInvocation(Object obj) { this.obj=obj; } @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { //调用目标文件的方法 Object resulet = method.invoke(obj,args); //增强方法 System.out.println(&quot;向客户发送短信&quot;); return resulet; } }2.获取代理类，调用取钱方法 public class ProxyTest { public static void main(String[] args) throws Exception { // 获取银行卡操作实现类 IBankCardService bankCard = new BankCardServiceImpl(); // 获取银行卡操作类的代理类 IBankCardService proxyBank = (IBankCardService)Proxy.newProxyInstance(bankCard.getClass().getClassLoader(), bankCard.getClass().getInterfaces(),new SendMessageInvocation(bankCard)); proxyBank.outMoney(&quot;9527&quot;); } } 打印结果: 向银行卡账号为:9527的账户取钱 向客户发送短信用JDK提供的代理类，很完美的解决了，不写代理类，直接写增强方法，直接就获取到目标的代理类。 三、动态代理的应用​ 设计模式中有一个设计原则是开闭原则：软件中对于扩展是开放的，对于修改是封闭的。再不改变源码的情况下，拓展它的行为。 ​ 工作中接收了很多以前的代码，里面的逻辑让人摸不透，就可以使用代理类进行增强。 ​ Spring的AOP就是Java的动态代理来实现的切面编程。 ​ RPC框架，框架本身不知道要调用哪些接口，哪些方法。这是框架可以一个创建代理类给客户端使用。 ​ 实际开发中的，通用异常处理，通用日志处理，事物处理都可以用到动态代理。 四、总结优点： ​ 动态代理类简化了代码编程工作，提高了软件的可扩展性。 缺点： ​ JDK动态代理只能代理有接口的实现类，没有接口的类就不能用JDK的动态代理。（Cglib动态代理可以对没有接口的类实现代理）]]></content>
      <categories>
        <category>java基础</category>
      </categories>
      <tags>
        <tag>java基础</tag>
        <tag>后端</tag>
        <tag>动态代理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Harbor镜像仓库的安装与配置]]></title>
    <url>%2Fblog%2F2019%2F06%2F06%2FHarbor%E9%95%9C%E5%83%8F%E4%BB%93%E5%BA%93%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[Harbor镜像仓库的安装与配置一、安装Harbor1.环境准备：​ 1.一台Centos7服务器(docker已安装, ip : 192.168.1.105),此服务器准备安装镜像仓库; ​ 2.一台Centos7服务器(docker已安装, ip : 192.168.1.106),此服务器测试从Harbor镜像仓库push和pull镜像用。 2.下载Harbor安装下载安装包：https://github.com/goharbor/harbor/releases 1.解压压缩包1tar zxvf harbor-online-installer-v1.8.1.tgz 2.配置harbor.yml文件1234567891011121314151617hostname: 192.168.1.105http:port will redirect to https port port: 80https: port: 443 certificate: /data/cert/192.168.1.105.crt private_key: /data/cert/192.168.1.105.keyharbor_admin_password: Harbor12345database: password: root123 data_volume: /data 3.运行prepare文件1./prepare 4.安装​ 服务器必须先安装Docker Compose 1./install.sh 安装完成,可以在浏览器中登录;但是使用另一台主机从镜像仓库中拉取镜像时将报错: 1http: server gave HTTP response to HTTPS client 原因是docker作为客户端,发送的是https请求,仓库未配置https. 二、配置Harbor的HTTPS访问可参考: https://goharbor.io/docs/2.0.0/install-config/configure-https/ 以下ip修改为Harbor服务器的ip 1.创建CA证书​ 生成CA证书私钥 1openssl genrsa -out ca.key 4096 ​ 生成CA证书 1234openssl req -x509 -new -nodes -sha512 -days 3650 \ -subj &quot;/C=CN/ST=Beijing/L=Beijing/O=example/OU=Personal/CN=192.168.1.105&quot;\ -key ca.key \ -out ca.crt 2.生成服务器证书​ 生成服务器证书私钥 1openssl genrsa -out 192.168.1.105.key 4096 ​ 生成服务器证书 1234openssl req -sha512 -new \ -subj &quot;/C=CN/ST=Beijing/L=Beijing/O=example/OU=Personal/CN=192.168.1.105&quot; \ -key 92.168.1.105.key \ -out 92.168.1.105.csr 3.生成 x509 v3扩展文件这里不能按照官网的安装,官网使用的事域名. 123456cat &gt; v3.ext &lt;&lt;-EOFauthorityKeyIdentifier=keyid,issuerbasicConstraints=CA:FALSEkeyUsage = digitalSignature, nonRepudiation, keyEncipherment, dataEnciphermentextendedKeyUsage = serverAuthsubjectAltName = 192.168.1.105 4.向Harbor和Docker提供证书1.向Harbor提供证书harbor.yml配置文件中,certificate和private_key文件路径在/data/cert/下,所以要把生成的服务器证书放在这个目录下 123mkdir /data/cert/cp 192.168.1.105.crt /data/cert/cp 192.168.1.105.key /data/cert/ 2.向docker提供证书将.crt文件转换为.cert文件,供docker使用 1openssl x509 -inform PEM -in yourdomain.com.crt -out yourdomain.com.cert 1234mkdir -p /etc/docker/certs.d/192.168.1.105/cp 192.168.1.105.cert /etc/docker/certs.d/192.168.1.105/cp 192.168.1.105.key /etc/docker/certs.d/192.168.1.105/cp ca.crt /etc/docker/certs.d/192.168.1.105/ 3.重启docker1systemctl restart docker 三、验证,测试1.浏览器使用https登录将192.168.1.105.crt拷贝至本机安装,浏览器就能用https正常访问. 2.测试docker能否正常登录1.使用192.168.1.106服务器登录Harbor1docker login 192.168.1.105 将报错: 1Error response from daemon: Get https://192.168.1.105/v2/: x509: certificate signed by unknown authority 2.制作的ca证书添加到信任（因为是自签名证书):将ca.crt拷贝至192.168.1.106主机 12mkdir –p /etc/docker/certs.d/192.168.1.105cp ca.crt /etc/docker/certs.d/192.168.1.105/ca.crt 1systemctl restart docker 出现:Login Succeeded,表示登录成功 四、推送和拉取镜像1.标记镜像1docker tag SOURCE_IMAGE[:TAG] 192.168.1.105/项目名/IMAGE[:TAG] 2.推送镜像到Harbor1docker push 10.82.13.105/项目名/IMAGE[:TAG] 3.从Harbor中拉取镜像1docker pull 10.82.13.105/项目名/IMAGE[:TAG]]]></content>
      <categories>
        <category>docker镜像仓库</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Lucene介绍与应用]]></title>
    <url>%2Fblog%2F2019%2F06%2F06%2FLucene%E4%BB%8B%E7%BB%8D%E4%B8%8E%E5%BA%94%E7%94%A8%2F</url>
    <content type="text"><![CDATA[Lucene介绍与应用一、全文检索介绍1.数据结构结构化数据：​ 指具有“固定格式” 或“限定长度”的数据； ​ 例如：数据库中的数据、元数据…… 非结构化数据​ 指不定长度或无固定格式的数据； ​ 例如：文本、图片、视频、图表…… 2.数据的搜索顺序扫描法​ 从第一个文件扫描到最后一个文件，把每一个文件内容从开头扫到结尾，直到扫完所有的文件。 全文检索法​ 将非结构化数据中的一部分信息提取出来，重新组织，建立索引，使其变得有一定结构，然后对此有一定结构的数据进行搜索，从而达到搜索相对较快的目的。 3.全文检索例如：新华字典。字典的拼音表和部首检字表就相当于字典的索引，我们可以通过查找索引从而找到具体的字解释。如果没有创建索引，就要从字典的首页一页页地去查找。 这种先建立索引，再对索引进行搜索的过程就叫全文检索(Full-text Search) 。 全文检索的核心创建索引：将从所有的结构化和非结构化数据提取信息，创建索引的过程。 搜索索引：就是得到用户的查询请求，搜索创建的索引，然后返回结果的过程。 4.倒排索引 倒排索引（英文：InvertedIndex），也称为反向索引，是一种索引方法，实现“单词-文档矩阵”的一种具体存储形式，常被用于存储在全文搜索下某个单词与文档的存储位置的映射，通过倒排索引，可以根据单词快速获取包含这个单词的文档列表。 倒排索引的结构主要由两个部分组成：“单词词典”和“倒排表”。 索引方法例子 ​ 3个文档内容为： ​ 1.php是过去最流行的语言。 ​ 2.java是现在最流行的语言。 ​ 3.Python是未来流行的语言。 倒排索引的创建​ 1.使用分词系统将文档切分成单词序列，每个文档就成了由由单词序列构成的数据流； ​ 2.给不同的单词赋予唯一的单词id,记录下对应的单词; ​ 3.同时记录单词出现的文档,形成倒排列表。每个单词都指向了文档(Document)链表。 倒排索引的查询​ 假如说用户需要查询: “现在流行” ​ 1.将用户输入进行分词,分为”现在”和”流行”; ​ 2.取出包含字符串“现在”的文档链表; ​ 3.取出包含字符串“流行”的文档链表; ​ 4.通过合并链表,找出包含有”现在”或者”流行”的链表。 倒排索引原理当然倒排索引的结构也不是上面说的那么简单，索引系统还可以记录除此之外的更多信息。词对应的倒排列表不仅记录了文档编号还记录了单词频率信息。词频信息在搜索结果时，是重要的排序依据。这里先了解下，后面的评分计算就要用到这个。 索引和搜索流程图 二、Lucene入门• Lucene是一套用于全文检索和搜寻的开源程序库，由Apache软件基金会支持和提供; • 基于java的全文检索工具包, Lucene并不是现成的搜索引擎产品，但可以用来制作搜索引擎产品； • 官网：http://lucene.apache.org/ 。 1.Lucene的总体结构 从lucene的总体架构图可以看出： ​ 1.Lucene库提供了创建索引和搜索索引的API。 ​ 2.应用程序需要做的就是收集文档数据，创建索引；通过用户输入查询索引的得到返回结果。 2.Lucene的几个基本概念Index（索引）：类似数据库的表的概念，但它完全没有约束，可以修改和添加里面的文档，文档里的内容可以任意定义。 Document（文档）：类似数据库内的行的概念，一个Index内会包含多个Document。 Field（字段）：一个Document会由一个或多个Field组成，分词就是对Field 分词。 Term（词语）和Term Dictionary（词典）：Lucene中索引和搜索的最小单位，一个Field会由一个或多个Term组成，Term是由Field经过Analyzer（分词）产生。Term Dictionary即Term词典，是根据条件查找Term的基本索引。 3.Lucene创建索引过程Lucene创建索引过程如下： 1.创建一个IndexWriter用来写索引文件，它有几个参数，INDEX_DIR就是索引文件所存放的位置，Analyzer便是用来 对文档进行词法分析和语言处理的。 2.创建一个Document代表我们要索引的文档。将不同的Field加入到文档中。不同类型的信息用不同的Field来表示 3.IndexWriter调用函数addDocument将索引写到索引文件夹中。 4.Lucene搜索过程搜索过程如下： 1.IndexReader将磁盘上的索引信息读入到内存，INDEX_DIR就是索引文件存放的位置。 2.创建IndexSearcher准备进行搜索。 3.创建Analyer用来对查询语句进行词法分析和语言处理。 4.创建QueryParser用来对查询语句进行语法分析。 5.QueryParser调用parser进行语法分析，形成查询语法树，放到Query中。 6.IndexSearcher调用search对查询语法树Query进行搜索，得到结果TopScoreDocCollector。 三、Lucene入门案例一1.案例一代码引入lucene的jar包 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394public class LuceneTest &#123; public static void main(String[] args) throws Exception &#123; // 1. 准备中文分词器 IKAnalyzer analyzer = new IKAnalyzer(); // 2. 创建索引 List&lt;String&gt; productNames = new ArrayList&lt;&gt;(); productNames.add(&quot;小天鹅TG100-1420WDXG&quot;); productNames.add(&quot;小天鹅TB80-easy60W 洗漂脱时间自由可调，京东微联智能APP手机控制&quot;); productNames.add(&quot;小天鹅TG90-1411DG 洗涤容量:9kg 脱水容量:9kg 显示屏:LED数码屏显示&quot;); productNames.add(&quot;小天鹅TP75-V602 流线蝶形波轮，超强喷淋漂洗&quot;); productNames.add(&quot;小天鹅TG100V20WDG 大件洗，无旋钮外观，智能WiFi&quot;); productNames.add(&quot;小天鹅TD80-1411DG 洗涤容量:8kg 脱水容量:8kg 显示屏:LED数码屏显示&quot;); productNames.add(&quot;海尔XQB90-BZ828 洗涤容量:9kg 脱水容量:9kg 显示屏:LED数码屏显示&quot;); productNames.add(&quot;海尔G100818HBG 极简智控面板，V6蒸汽烘干，深层洁净&quot;); productNames.add(&quot;海尔G100678HB14SU1 洗涤容量:10kg 脱水容量:10kg 显示屏:LED数码屏显&quot;); productNames.add(&quot;海尔XQB80-KM12688 智能自由洗，超净洗&quot;); productNames.add(&quot;海尔EG8014HB39GU1 手机智能，一键免熨烫，空气净化洗&quot;); productNames.add(&quot;海尔G100818BG 琥珀金机身，深层洁净，轻柔雪纺洗&quot;); productNames.add(&quot;海尔G100728BX12G 安全磁锁，健康下排水&quot;); productNames.add(&quot;西门子XQG80-WD12G4C01W 衣干即停，热风除菌，低噪音&quot;); productNames.add(&quot;西门子XQG80-WD12G4681W 智能烘干，变速节能，无刷电机&quot;); productNames.add(&quot;西门子XQG100-WM14U568LW 洗涤容量:10kg 脱水容量:10kg 显示屏:LED&quot;); productNames.add(&quot;西门子XQG80-WM10N1C80W 除菌、洗涤分离，防过敏程序&quot;); productNames.add(&quot;西门子XQG100-WM14U561HW 洗涤容量:10kg 脱水容量:10kg 显示屏:LED&quot;); productNames.add(&quot;西门子XQG80-WM12L2E88W 洗涤容量:8kg 脱水容量:8kg 显示屏:LED触摸&quot;); Directory index = createIndex(analyzer, productNames); // 3. 查询器 String keyword = &quot;西门子 LED&quot;; Query query = new QueryParser(&quot;name&quot;, analyzer).parse(keyword); // 4. 搜索 IndexReader reader = DirectoryReader.open(index); IndexSearcher searcher = new IndexSearcher(reader); int numberPerPage = 1000; System.out.printf(&quot;当前一共有%d条数据%n&quot;+&quot;&lt;br&gt;&quot;, productNames.size()); System.out.printf(&quot;查询关键字是：\&quot;%s\&quot;%n&quot;+&quot;&lt;br&gt;&quot;, keyword); ScoreDoc[] hits = searcher.search(query, numberPerPage).scoreDocs; // 5. 显示查询结果 showSearchResults(searcher, hits, query, analyzer); // 6. 关闭查询 reader.close(); &#125; private static void showSearchResults(IndexSearcher searcher, ScoreDoc[] hits, Query query, IKAnalyzer analyzer) throws Exception &#123; System.out.println(&quot;找到 &quot; + hits.length + &quot; 个命中. &lt;br&gt;&quot;); System.out.println(&quot;序号\t匹配度得分\t结果 &lt;br&gt;&quot;); SimpleHTMLFormatter simpleHTMLFormatter = new SimpleHTMLFormatter(&quot;&lt;span style=&apos;color:red&apos;&gt;&quot;, &quot;&lt;/span&gt;&quot;); Highlighter highlighter = new Highlighter(simpleHTMLFormatter, new QueryScorer(query)); for (int i = 0; i &lt; hits.length; ++i) &#123; ScoreDoc scoreDoc= hits[i]; int docId = scoreDoc.doc; Document d = searcher.doc(docId); List&lt;IndexableField&gt; fields = d.getFields(); System.out.print((i + 1)); System.out.print(&quot;\t&quot; + scoreDoc.score); for (IndexableField f : fields) &#123; TokenStream tokenStream = analyzer.tokenStream(f.name(), new StringReader(d.get(f.name()))); String fieldContent = highlighter.getBestFragment(tokenStream, d.get(f.name())); System.out.print(&quot;\t&quot; + fieldContent); &#125; System.out.println(&quot;&lt;br&gt;&quot;); &#125; &#125; private static Directory createIndex(IKAnalyzer analyzer, List&lt;String&gt; products) throws IOException &#123; //存在内存中,新建一个词典 Directory index = new RAMDirectory(); IndexWriterConfig config = new IndexWriterConfig(analyzer); IndexWriter writer = new IndexWriter(index, config); for (String name : products) &#123; addDoc(writer, name); &#125; writer.close(); return index; &#125; /** * 添加文档内容 * @param w * @param name * @throws IOException */ private static void addDoc(IndexWriter w, String name) throws IOException &#123; //创建一个文档 Document doc = new Document(); doc.add(new TextField(&quot;name&quot;, name, Field.Store.YES)); w.addDocument(doc); &#125;&#125; 2.代码解析创建索引123456789101112131415161718private static Directory createIndex(IKAnalyzer analyzer, List&lt;String&gt; products) throws IOException &#123; //存在内存中,新建一个词典 Directory index = new RAMDirectory(); IndexWriterConfig config = new IndexWriterConfig(analyzer); IndexWriter writer = new IndexWriter(index, config); for (String name : products) &#123; addDoc(writer, name); &#125; writer.close(); return index;&#125;private static void addDoc(IndexWriter w, String name) throws IOException &#123; //创建一个文档 Document doc = new Document(); doc.add(new TextField(&quot;name&quot;, name, Field.Store.YES)); w.addDocument(doc);&#125; 上面代码是将List中的内容保存在文档中，使用analyzer分词器分词，创建索引，索引保存在内存中。 IndexWriter 对象用来写索引的。 查询索引1234567891011121314// 3. 查询器String keyword = &quot;西门子 智能&quot;;Query query = new QueryParser(&quot;name&quot;, analyzer).parse(keyword);// 4. 搜索IndexReader reader = DirectoryReader.open(index);IndexSearcher searcher = new IndexSearcher(reader);int numberPerPage = 1000;System.out.printf(&quot;当前一共有%d条数据%n&quot;, productNames.size());System.out.printf(&quot;查询关键字是：\&quot;%s\&quot;%n&quot;, keyword);ScoreDoc[] hits = searcher.search(query, numberPerPage).scoreDocs;// 5. 显示查询结果showSearchResults(searcher, hits, query, analyzer);// 6. 关闭查询reader.close(); 上面代码是查询代码，首先对构建查询条件Query对象，读取索引，创建IndexSearcher 查询对象，传入查询条件，得到查询结果，将结果解析出来，返回。 分词器创建索引和查询都要用到分词器，在Lucene中分词主要依靠Analyzer类解析实现。Analyzer类是一个抽象类，分词的具体规则是由子类实现的，不同的语言规则，要有不同的分词器， Lucene默认的StandardAnalyzer是不支持中文的分词。 代码中用到了IKAnalyzer分词器，IKAnalyzer是第三方实现的分词器，继承自Lucene的Analyzer类，针对中文文本进行处理的分词器。 打分机制 从案例返回结果来看,有一列匹配度得分,得分越高的排在越前面,排在前面的查询结果也越准确。 打分公式： ​ Lucene库也实现了上面的打分算法，查询结果也会根据分数进行排序。 高亮显示12SimpleHTMLFormatter simpleHTMLFormatter = new SimpleHTMLFormatter(&quot;&lt;span style=&apos;color:red&apos;&gt;&quot;, &quot;&lt;/span&gt;&quot;);Highlighter highlighter = new Highlighter(simpleHTMLFormatter, new QueryScorer(query)); 将查询结果放到html页面，就会发现查询结果里关键字被标记为红色。在 Lucene库的org.apache.lucene.search.highlight包中提供了关于高亮显示检索关键字的方法，可以对返回的结果中出现了的关键字进行标记。 四、Lucene入门案例二1.案例介绍 1.将14万条商品详细信息到mysql数据库; 2.使用Lucene库创建索引; 3.使用Luncene查询索引,并做分页操作,得到返回查询到的数据,并记录查询时长; 4.使用JDBC连接mysql数据库,采用like查询,对商品进行分页操作,返回查询到的数据,记录查询时长; 5.比较mysql的模糊查询与Lucene全文检索查询。 2.案例二代码引入lucene的jar包,和mysql的驱动包,创建数据库product表,插入数据. 12345678910111213141516171819202122232425262728293031323334/** * 商品bean类 * @author yizl * */public class Product &#123; /** * 商品id */ private int id; /** * 商品名称 */ private String name; /** * 商品类型 */ private String category; /** * 商品价格 */ private float price; /** * 商品产地 */ private String place; /** * 商品条形码 */ private String code; ...... &#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165public class TestLucene &#123; private static ProductDao dao = new ProductDao(); public static void main(String[] args) throws Exception &#123; // 1. 准备中文分词器 IKAnalyzer analyzer = new IKAnalyzer(); // 2. 索引 Directory index = createIndex(analyzer); // 3. 查询器 Scanner s = new Scanner(System.in); while (true) &#123; System.out.print(&quot;请输入查询关键字：&quot;); String keyword = s.nextLine(); System.out.println(&quot;当前关键字是：&quot; + keyword); long start = System.currentTimeMillis(); // 查询名字字段 Query query = new QueryParser(&quot;name&quot;, analyzer).parse(keyword); // 4. 搜索 IndexReader reader = DirectoryReader.open(index); IndexSearcher searcher = new IndexSearcher(reader); ScoreDoc[] hits = pageSearch(query, searcher, 1, 10); // 5. 显示查询结果 showSearchResults(searcher, hits, query, analyzer); // 6. 关闭查询 reader.close(); System.out.println(&quot;使用Lucene查询索引,耗时:&quot; + (System.currentTimeMillis() - start) + &quot;毫秒&quot;); System.out.println(&quot;-----------------------分割线-------------------------------&quot;); // 7.通过数据库进行模糊查询 selectProductOfName(keyword); &#125; &#125; /** * 通过mysql商品名查询 */ private static void selectProductOfName(String str) &#123; long start = System.currentTimeMillis(); ResultBean&lt;List&lt;Product&gt;&gt; resultBean = dao.selectProductOfName(str, 1, 10); PageBean pageBean = resultBean.getPageBean(); List&lt;Product&gt; products = resultBean.getData(); System.out.println(&quot;查询出的总条数\t:&quot; + pageBean.getTotal() + &quot;条&quot;); System.out.println(&quot;当前第&quot; + pageBean.getPageNow() + &quot;页,每页显示&quot; + pageBean.getPageSize() + &quot;条数据&quot;); System.out.println(&quot;序号\t结果&quot;); for (int i = 0; i &lt; products.size(); i++) &#123; Product product = products.get(i); System.out.print((i + 1)); System.out.print(&quot;\t&quot; + product.getId()); System.out.print(&quot;\t&quot; + product.getName()); System.out.print(&quot;\t&quot; + product.getPrice()); System.out.print(&quot;\t&quot; + product.getPlace()); System.out.print(&quot;\t&quot; + product.getCode()); System.out.println(&quot;&lt;br&gt;&quot;); &#125; System.out.println(&quot;使用mysql查询,耗时:&quot; + (System.currentTimeMillis() - start) + &quot;毫秒&quot;); &#125; /** * 显示找到的结果 * * @param searcher * @param hits * @param query * @param analyzer * @throws Exception */ private static void showSearchResults(IndexSearcher searcher, ScoreDoc[] hits, Query query, IKAnalyzer analyzer) throws Exception &#123; System.out.println(&quot;序号\t匹配度得分\t结果&quot;); for (int i = 0; i &lt; hits.length; ++i) &#123; ScoreDoc scoreDoc = hits[i]; int docId = scoreDoc.doc; Document d = searcher.doc(docId); List&lt;IndexableField&gt; fields = d.getFields(); System.out.print((i + 1)); System.out.print(&quot;\t&quot; + scoreDoc.score); for (IndexableField f : fields) &#123; System.out.print(&quot;\t&quot; + d.get(f.name())); &#125; System.out.println(&quot;&lt;br&gt;&quot;); &#125; &#125; /** * 分页查询 * * @param query * @param searcher * @param pageNow * 当前第几页 * @param pageSize * 每页显示条数 * @return * @throws IOException */ private static ScoreDoc[] pageSearch(Query query, IndexSearcher searcher, int pageNow, int pageSize) throws IOException &#123; TopDocs topDocs = searcher.search(query, pageNow * pageSize); System.out.println(&quot;查询到的总条数\t&quot; + topDocs.totalHits); System.out.println(&quot;当前第&quot; + pageNow + &quot;页,每页显示&quot; + pageSize + &quot;条数据&quot;); ScoreDoc[] alllScores = topDocs.scoreDocs; List&lt;ScoreDoc&gt; hitScores = new ArrayList&lt;&gt;(); int start = (pageNow - 1) * pageSize; int end = pageSize * pageNow; for (int i = start; i &lt; end; i++) hitScores.add(alllScores[i]); ScoreDoc[] hits = hitScores.toArray(new ScoreDoc[] &#123;&#125;); return hits; &#125; /** * 创建Index,将数据存入内存中 * * @param analyzer * @return * @throws IOException */ private static Directory createIndex(IKAnalyzer analyzer) throws IOException &#123; long start = System.currentTimeMillis(); Directory index = new RAMDirectory(); IndexWriterConfig config = new IndexWriterConfig(analyzer); IndexWriter writer = new IndexWriter(index, config); List&lt;Product&gt; products = dao.selectAllProduct(); int total = products.size(); int count = 0; int per = 0; int oldPer = 0; for (Product p : products) &#123; addDoc(writer, p); count++; per = count * 100 / total; if (per != oldPer) &#123; oldPer = per; System.out.printf(&quot;索引中，总共要添加 %d 条记录，当前添加进度是： %d%% %n&quot;, total, per); &#125; &#125; System.out.println(&quot;索引创建耗时:&quot; + (System.currentTimeMillis() - start) + &quot;毫秒&quot;); writer.close(); return index; &#125; /** * 往lucene中添加字段 * * @param w * @param p * @throws IOException */ private static void addDoc(IndexWriter w, Product p) throws IOException &#123; Document doc = new Document(); doc.add(new TextField(&quot;id&quot;, String.valueOf(p.getId()), Field.Store.YES)); doc.add(new TextField(&quot;name&quot;, p.getName(), Field.Store.YES)); doc.add(new TextField(&quot;category&quot;, p.getCategory(), Field.Store.YES)); doc.add(new TextField(&quot;price&quot;, String.valueOf(p.getPrice()), Field.Store.YES)); doc.add(new TextField(&quot;place&quot;, p.getPlace(), Field.Store.YES)); doc.add(new TextField(&quot;code&quot;, p.getCode(), Field.Store.YES)); w.addDocument(doc); &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221public class ProductDao &#123; private static String url = &quot;jdbc:mysql://localhost:3306/lucene?useUnicode=true&amp;characterEncoding=utf8&quot;; private static String user = &quot;root&quot;; private static String password = &quot;root&quot;; public static Connection getConnection() throws ClassNotFoundException, SQLException &#123; Connection conn = null; // 通过工具类获取连接对象 Class.forName(&quot;com.mysql.jdbc.Driver&quot;); conn = DriverManager.getConnection(url, user, password); return conn; &#125; /** * 批量增加商品 * @param pList */ public void insertProduct(List&lt;Product&gt; pList) &#123; String insertProductTop=&quot;INSERT INTO `product` (`id`, `name`, &quot; + &quot;`category`, `price`, `place`, `code`) VALUES &quot;; Connection conn = null; Statement stmt = null; try &#123; conn = getConnection(); // 3.创建Statement对象 stmt = conn.createStatement(); int count=0; // 4.sql语句 StringBuffer sb = new StringBuffer(); for (int i = 0,len=pList.size(); i &lt; len; i++) &#123; Product product = pList.get(i); sb.append(&quot;(&quot; + product.getId() + &quot;,&apos;&quot; + product.getName() + &quot;&apos;,&apos;&quot; + product.getCategory()+ &quot;&apos;,&quot; + product.getPrice() + &quot;,&apos;&quot; + product.getPlace() + &quot;&apos;,&apos;&quot; + product.getCode() + &quot;&apos;)&quot;); if (i==len-1) &#123; sb.append(&quot;;&quot;); break; &#125;else &#123; sb.append(&quot;,&quot;); &#125; //数据量太大会导致一次执行不了,一次最多执行20000条 if(i%20000==0&amp;&amp;i!=0) &#123; sb.deleteCharAt(sb.length()-1); sb.append(&quot;;&quot;); String sql = insertProductTop+sb; count += stmt.executeUpdate(sql); //将sb清空 sb.delete(0, sb.length()); &#125; &#125; String sql = insertProductTop+sb; // 5.执行sql count += stmt.executeUpdate(sql); System.out.println(&quot;影响了&quot; + count + &quot;行&quot;); &#125; catch (Exception e) &#123; e.printStackTrace(); throw new RuntimeException(e); &#125; finally &#123; close(conn, stmt); &#125; &#125; /** * 关闭资源 * @param conn * @param stmt */ private void close(Connection conn, Statement stmt) &#123; // 关闭资源 if (stmt != null) &#123; try &#123; stmt.close(); &#125; catch (SQLException e) &#123; e.printStackTrace(); throw new RuntimeException(e); &#125; &#125; if (conn != null) &#123; try &#123; conn.close(); &#125; catch (SQLException e) &#123; e.printStackTrace(); throw new RuntimeException(e); &#125; &#125; &#125; // public void deleteAllProduct() &#123; Connection conn = null; Statement stmt = null; try &#123; conn = getConnection(); // 3.创建Statement对象 stmt = conn.createStatement(); // 4.sql语句 String sql = &quot;delete from product&quot;; // 5.执行sql int count = stmt.executeUpdate(sql); System.out.println(&quot;影响了&quot; + count + &quot;行&quot;); &#125; catch (Exception e) &#123; e.printStackTrace(); throw new RuntimeException(e); &#125; finally &#123; // 关闭资源 close(conn, stmt); &#125; &#125; /** * 查询所有商品 */ public List&lt;Product&gt; selectAllProduct() &#123; List&lt;Product&gt; pList=new ArrayList&lt;&gt;(); Connection conn = null; Statement stmt = null; try &#123; conn = getConnection(); // 3.创建Statement对象 stmt = conn.createStatement(); // 4.sql语句 String sql = &quot;select * from product&quot;; // 5.执行sql ResultSet rs = stmt.executeQuery(sql); while (rs.next()) &#123; Product product=new Product(); product.setId(rs.getInt(&quot;id&quot;)); product.setName(rs.getString(&quot;name&quot;)); product.setCategory(rs.getString(&quot;category&quot;)); product.setPlace(rs.getString(&quot;place&quot;)); product.setPrice(rs.getFloat(&quot;price&quot;)); product.setCode(rs.getString(&quot;code&quot;)); pList.add(product); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); throw new RuntimeException(e); &#125; finally &#123; // 关闭资源 close(conn, stmt); &#125; return pList; &#125; /** * 通过商品名模糊匹配商品 * @param strName * @param pageNow * @param pageSize * @return */ public ResultBean&lt;List&lt;Product&gt;&gt; selectProductOfName(String strName, int pageNow, int pageSize) &#123; ResultBean&lt;List&lt;Product&gt;&gt; resultBean=new ResultBean&lt;List&lt;Product&gt;&gt;(); PageBean pageBean =new PageBean(); pageBean.setPageNow(pageNow); pageBean.setPageSize(pageSize); List&lt;Product&gt; pList=new ArrayList&lt;&gt;(); Connection conn = null; PreparedStatement pstmt = null; try &#123; conn = getConnection(); // sql语句 String sql = &quot;SELECT id,name,category,place,price,code FROM product&quot; + &quot; where name like ? limit &quot;+(pageNow-1)*pageSize+&quot;,&quot;+pageSize; // 3.创建PreparedStatement对象,sql预编译 pstmt = conn.prepareStatement(sql); // 4.设定参数 pstmt.setString(1, &quot;%&quot; + strName + &quot;%&quot; ); // 5.执行sql,获取查询的结果集 ResultSet rs = pstmt.executeQuery(); while (rs.next()) &#123; Product product=new Product(); product.setId(rs.getInt(&quot;id&quot;)); product.setName(rs.getString(&quot;name&quot;)); product.setCategory(rs.getString(&quot;category&quot;)); product.setPlace(rs.getString(&quot;place&quot;)); product.setPrice(rs.getFloat(&quot;price&quot;)); product.setCode(rs.getString(&quot;code&quot;)); pList.add(product); &#125; String selectCount = &quot;SELECT count(1) c FROM product&quot; + &quot; where name like ? &quot;; pstmt = conn.prepareStatement(selectCount); pstmt.setString(1, &quot;%&quot; + strName + &quot;%&quot; ); ResultSet rs1 = pstmt.executeQuery(); int count=0; while (rs1.next()) &#123; count = rs1.getInt(&quot;c&quot;); &#125; pageBean.setTotal(count); resultBean.setPageBean(pageBean); resultBean.setData(pList); &#125; catch (Exception e) &#123; e.printStackTrace(); throw new RuntimeException(e); &#125; finally &#123; // 关闭资源 if (pstmt != null) &#123; try &#123; pstmt.close(); &#125; catch (SQLException e) &#123; e.printStackTrace(); throw new RuntimeException(e); &#125; &#125; if (conn != null) &#123; try &#123; conn.close(); &#125; catch (SQLException e) &#123; e.printStackTrace(); throw new RuntimeException(e); &#125; &#125; &#125; return resultBean; &#125;&#125; 12345678910111213141516171819202122232425/** * 返回结果bean * @author yizl * * @param &lt;T&gt; */public class ResultBean&lt;T&gt; &#123; /** * 分页信息 */ private PageBean pageBean; /** * 状态码 */ private Integer code; /** * 提示信息 */ private String msg; /** * 返回数据 */ private T data; 12345678910111213141516171819/** * 分页bean * @author yizl * */public class PageBean &#123; /** * 当前页数 */ private Integer pageNow; /** * 每页条数 */ private Integer pageSize; /** * 总数 */ private Integer total; 4.Lucene的分页查询123456789101112131415private static ScoreDoc[] pageSearch(Query query, IndexSearcher searcher, int pageNow, int pageSize)throws IOException &#123;TopDocs topDocs = searcher.search(query, pageNow * pageSize);System.out.println(&quot;查询到的总条数\t&quot; + topDocs.totalHits);System.out.println(&quot;当前第&quot; + pageNow + &quot;页,每页显示&quot; + pageSize + &quot;条数据&quot;);ScoreDoc[] alllScores = topDocs.scoreDocs;List&lt;ScoreDoc&gt; hitScores = new ArrayList&lt;&gt;();int start = (pageNow - 1) * pageSize;int end = pageSize * pageNow;for (int i = start; i &lt; end; i++)hitScores.add(alllScores[i]);ScoreDoc[] hits = hitScores.toArray(new ScoreDoc[] &#123;&#125;);return hits;&#125; 先把所有的命中数查询出来，在进行分页，有点是查询快，缺点是内存消耗大。 5.结果比较分析1.14万条数据,从创建lucene索引耗时:11678毫秒,创建索引还是比较耗时的,但是索引只用创建一次,后面都查询都可以使用；2.从查询时间来看,使用Lucene查询,基本都在10ms左右,mysql查询耗时在150ms以上,查询速度方面有很大的提升，特别是数据量大的时候更加明显； 3.从查询精准度来说，输入单个的词语可能都能查询到结果，输入组合词语，mysql可以匹配不了，Lucene依然可以查询出来，将匹配度高的结果排在前面，更精准。 6.Lucene索引与mysql数据库对比 Lucene全文检索 mysql数据库 索引 将数据源中的数据–建立反向索引,查询快 对于like查询来说,传统数据库的索引不起作用,还是要全表扫描，查询慢 匹配效果 词元(term)匹配,通过语言分析接口进行关键字拆分，匹配度高 模糊匹配,可能不能匹配相关的词组 匹配度 有匹配度算法,匹配度高的得分高排前面 无匹配程度算法,随机排列 关键字标记 提供高亮显示的Api,可以对查询结果的关键字高亮标记 没有直接使用的api,需要自己封装 五、总结首先我们了解全文检索方法，全文检索搜索非结构化数据速度快等优点，倒排索引是现在最常用的全文检索方法，索引的核心就是怎么创建索引和查询索引。至于怎么实现创建和查询，Apache软件基金会很贴心的为我们Java程序员提供了Lucene开源库，它为我们提供了创建和查询索引的api，这就是我们学习Lucene的目的。]]></content>
      <categories>
        <category>全文检索技术</category>
      </categories>
      <tags>
        <tag>Lucene</tag>
      </tags>
  </entry>
</search>
